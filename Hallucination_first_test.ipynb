{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>tgt</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't worry, it's only temporary.</td>\n",
       "      <td>Don't worry. It's only temporary.</td>\n",
       "      <td>Не волнуйся. Это только временно.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom is never where he should be.</td>\n",
       "      <td>Tom is never where he's supposed to be.</td>\n",
       "      <td>Тома никогда нет там, где он должен быть.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's hard for me to work with Tom.</td>\n",
       "      <td>I have trouble working with Tom.</td>\n",
       "      <td>Мне сложно работать с Томом.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Water, please.</td>\n",
       "      <td>I'd like some water.</td>\n",
       "      <td>Воду, пожалуйста.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I didn't expect Tom to betray me.</td>\n",
       "      <td>I didn't think that Tom would betray me.</td>\n",
       "      <td>Я не ожидал, что Том предаст меня.</td>\n",
       "      <td>either</td>\n",
       "      <td>MT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hyp   \n",
       "0   Don't worry, it's only temporary.  \\\n",
       "1    Tom is never where he should be.   \n",
       "2  It's hard for me to work with Tom.   \n",
       "3                      Water, please.   \n",
       "4   I didn't expect Tom to betray me.   \n",
       "\n",
       "                                        tgt   \n",
       "0         Don't worry. It's only temporary.  \\\n",
       "1   Tom is never where he's supposed to be.   \n",
       "2          I have trouble working with Tom.   \n",
       "3                      I'd like some water.   \n",
       "4  I didn't think that Tom would betray me.   \n",
       "\n",
       "                                         src     ref task model  \n",
       "0          Не волнуйся. Это только временно.  either   MT        \n",
       "1  Тома никогда нет там, где он должен быть.  either   MT        \n",
       "2               Мне сложно работать с Томом.  either   MT        \n",
       "3                          Воду, пожалуйста.  either   MT        \n",
       "4         Я не ожидал, что Том предаст меня.  either   MT        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_json(r\"SHROOM_train\\train.model-agnostic.json\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2024, 2616,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"this are words\"\n",
    "tokens = tokenizer.encode_plus(s,  return_tensors=\"pt\")\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0668,  0.1709]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"vec_hyp\"] = data_train[\"hyp\"].map( lambda x : model(**tokenizer(x, return_tensors=\"pt\")) )\n",
    "data_train[\"vec_tgt\"] = data_train[\"tgt\"].map( lambda x : model(**tokenizer(x, return_tensors=\"pt\")) )\n",
    "data_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
