{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/data1/malto/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Quantized LLM and Few-Shot Learning to Generate Synthetic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "#model_name_or_path = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
    "#revision = \"gptq-3bit-128g-actorder_True\"\n",
    "\n",
    "model_name_or_path = \"TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ\"\n",
    "revision = \"gptq-8bit-32g-actorder_True\"\n",
    "\n",
    "# tasks MT, DM, PG\n",
    "\n",
    "TASK_TYPE = \"PG\"\n",
    "BATCH_SIZE = 40\n",
    "BASE_DIR = Path(\"/data1/malto/shroom\")\n",
    "\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-128g-actorder_True\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=revision)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "if tokenizer.pad_token == None: # apparently Mixtral does not have a padding token in tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc34eec0afd74ecbb1a7abb83895488c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src'],\n",
       "    num_rows: 125\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"json\", data_files=[\"/data1/malto/shroom/val.model-agnostic.json\"]).shuffle()\n",
    "ds['train'] = ds['train'].filter(lambda x: x['task'] == TASK_TYPE)\n",
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\n",
      "\n",
      "Example 1\n",
      "<HYP>: It's a little bit too dangerous.\n",
      "<TGT>: It is very dangerous.\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 2\n",
      "<HYP>: Tell me what the problem is here.\n",
      "<TGT>: What seems to be the problem?\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 3\n",
      "<HYP>: This ain't going to end up too good.\n",
      "<TGT>: This is not gonna end well.\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 4\n",
      "<HYP>: This won't take more than a second, okay?\n",
      "<TGT>: This won't take long.\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 5\n",
      "<HYP>: I'm going to take a good care of you now.\n",
      "<TGT>: I'm gonna look after you.\n",
      "<LABEL>: Not Hallucination\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = 5\n",
    "num_samples = len(ds['train'])\n",
    "examples = \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\\n\"\n",
    "\n",
    "for i in range(num_examples):\n",
    "    num = int(random() * num_samples)\n",
    "    hyp = ds['train'][num]['hyp']\n",
    "    tgt = ds['train'][num]['tgt']\n",
    "    label = ds['train'][num]['label']\n",
    "    examples += f\"\\nExample {i+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: {label}\\n\"\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(mapped_ds):\n",
    "    hyp = mapped_ds[\"hyp\"]\n",
    "    tgt = mapped_ds[\"tgt\"] if mapped_ds['ref'] != \"src\" else mapped_ds['src']\n",
    "    prompt = f\"{examples}\\n Example {num_examples+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: \"\n",
    "    return {'prompts' : prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fa1d0525a346509545482dab8d6432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prompt)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(mapped_ds):\n",
    "    input_ids = tokenizer(mapped_ds['prompts'], padding=True, truncation=True, max_length=500, return_tensors='pt').input_ids.cuda()\n",
    "    output = model.generate(inputs=input_ids, temperature=0.01, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=5)\n",
    "    decoded_output = tokenizer.batch_decode(output)\n",
    "    return {'output' : decoded_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb06413966f4aaabbf475f082bd7e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/fborra/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_synthetic_label(mapped_ds):\n",
    "    syn_labels = []\n",
    "    for item in mapped_ds['output']:\n",
    "        if \"Not\" in item.splitlines()[-1]:\n",
    "            syn_labels.append(\"Not Hallucination\")\n",
    "        else:\n",
    "            syn_labels.append(\"Hallucination\")\n",
    "    return {'synthetic_labels' : syn_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551c1ca14a7b42f7bafcf372c929969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output', 'synthetic_labels'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(extract_synthetic_label, batched=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for a, b in zip(ds['train']['label'], ds['train']['synthetic_labels']):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['Hallucination',\n",
       "  'Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination'],\n",
       " 'label': 'Hallucination',\n",
       " 'model': '',\n",
       " 'ref': 'either',\n",
       " 'hyp': 'This is a very important, very important service route, Mr. President.',\n",
       " 'task': 'PG',\n",
       " 'tgt': 'This route is for essential traffic only.',\n",
       " 'p(Hallucination)': 0.8,\n",
       " 'src': 'This is an essential service route.',\n",
       " 'prompts': \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: It's a little bit too dangerous.\\n<TGT>: It is very dangerous.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: Tell me what the problem is here.\\n<TGT>: What seems to be the problem?\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: This ain't going to end up too good.\\n<TGT>: This is not gonna end well.\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: This won't take more than a second, okay?\\n<TGT>: This won't take long.\\n<LABEL>: Not Hallucination\\n\\nExample 5\\n<HYP>: I'm going to take a good care of you now.\\n<TGT>: I'm gonna look after you.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: This is a very important, very important service route, Mr. President.\\n<TGT>: This route is for essential traffic only.\\n<LABEL>: \",\n",
       " 'output': \"</s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: It's a little bit too dangerous.\\n<TGT>: It is very dangerous.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: Tell me what the problem is here.\\n<TGT>: What seems to be the problem?\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: This ain't going to end up too good.\\n<TGT>: This is not gonna end well.\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: This won't take more than a second, okay?\\n<TGT>: This won't take long.\\n<LABEL>: Not Hallucination\\n\\nExample 5\\n<HYP>: I'm going to take a good care of you now.\\n<TGT>: I'm gonna look after you.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: This is a very important, very important service route, Mr. President.\\n<TGT>: This route is for essential traffic only.\\n<LABEL>:  Hallucination\\n\\n\",\n",
       " 'synthetic_labels': 'Hallucination'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels for New Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caadc5ec614142e6b0288a5b0c11957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_empty_column():\n",
    "    tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / \"train.model-agnostic.json\")])\n",
    "    tr_ds = tr_ds.map(lambda x: {'labels' : []})\n",
    "    tr_ds['train'] = tr_ds['train'].filter(lambda x: x['task'] == TASK_TYPE)\n",
    "    tr_ds['train'].to_json(str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\"))\n",
    "\n",
    "#create_empty_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc70966ed22428fa5cc353dc966bf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe313c6c4984e3e9180761f12093635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94488bcd0cae4cfca66f496b1919f0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5995b7df8ab644ed804a411dbeea461d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a8ee41b371489eb9ea804e747c59e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a2d609d4924981b256200ce8a3f9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(extract_synthetic_label, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c5e6ab6c240d3bc2958b1d1c07975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_prediction(mapped_ds):\n",
    "    mapped_ds['labels'].append(mapped_ds['synthetic_labels'])\n",
    "    return mapped_ds\n",
    "\n",
    "tr_ds = tr_ds.map(add_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': '♪ I got the joy, joy, joy, joy Down in my heart ♪',\n",
       " 'src': 'I got the joy, joy, joy, joy Down in my heart',\n",
       " 'task': 'PG',\n",
       " 'ref': 'src',\n",
       " 'tgt': '',\n",
       " 'model': '',\n",
       " 'labels': ['Not Hallucination'],\n",
       " 'prompts': \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: It's a little bit too dangerous.\\n<TGT>: It is very dangerous.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: Tell me what the problem is here.\\n<TGT>: What seems to be the problem?\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: This ain't going to end up too good.\\n<TGT>: This is not gonna end well.\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: This won't take more than a second, okay?\\n<TGT>: This won't take long.\\n<LABEL>: Not Hallucination\\n\\nExample 5\\n<HYP>: I'm going to take a good care of you now.\\n<TGT>: I'm gonna look after you.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: ♪ I got the joy, joy, joy, joy Down in my heart ♪\\n<TGT>: I got the joy, joy, joy, joy Down in my heart\\n<LABEL>: \",\n",
       " 'output': \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: It's a little bit too dangerous.\\n<TGT>: It is very dangerous.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: Tell me what the problem is here.\\n<TGT>: What seems to be the problem?\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: This ain't going to end up too good.\\n<TGT>: This is not gonna end well.\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: This won't take more than a second, okay?\\n<TGT>: This won't take long.\\n<LABEL>: Not Hallucination\\n\\nExample 5\\n<HYP>: I'm going to take a good care of you now.\\n<TGT>: I'm gonna look after you.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: ♪ I got the joy, joy, joy, joy Down in my heart ♪\\n<TGT>: I got the joy, joy, joy, joy Down in my heart\\n<LABEL>:  Not Hallucination\\n\",\n",
       " 'synthetic_labels': 'Not Hallucination'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b979bf407740f796a062a1248366b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19613934"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'].to_json(str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
