{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/data1/malto/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Quantized LLM and Few-Shot Learning to Generate Synthetic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "#model_name_or_path = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
    "#revision = \"gptq-3bit-128g-actorder_True\"\n",
    "\n",
    "model_name_or_path = \"TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ\"\n",
    "revision = \"gptq-8bit-32g-actorder_True\"\n",
    "\n",
    "# tasks MT, DM, PG\n",
    "\n",
    "#TASK_TYPE = \"MT\"\n",
    "BATCH_SIZE = 40\n",
    "BASE_DIR = Path(\"/data1/malto/shroom\")\n",
    "\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-128g-actorder_True\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=revision)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "if tokenizer.pad_token == None: # apparently Mixtral does not have a padding token in tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src'],\n",
       "    num_rows: 499\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"json\", data_files=[\"/data1/malto/shroom/val.model-agnostic.json\"]).shuffle()\n",
    "#ds['train'] = ds['train'].filter(lambda x: x['task'] == TASK_TYPE)\n",
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\n",
      "\n",
      "Example 1\n",
      "<HYP>: Capable of being parachuted.\n",
      "<TGT>: Capable of being deployed by parachute.\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 2\n",
      "<HYP>: (vulgar, slang, derogatory) A contemptible person.\n",
      "<TGT>: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\n",
      "<LABEL>: Hallucination\n",
      "\n",
      "Example 3\n",
      "<HYP>: Let's go?\n",
      "<TGT>: Should we go?\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 4\n",
      "<HYP>: (nautical) A service in which the crew of a vessel does not speak.\n",
      "<TGT>: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\n",
      "<LABEL>: Hallucination\n",
      "\n",
      "Example 5\n",
      "<HYP>: (informal) A man who works out at a gym.\n",
      "<TGT>: (slang) A man who spends much of his free time working out at a gym.\n",
      "<LABEL>: Not Hallucination\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = 5\n",
    "num_samples = len(ds['train'])\n",
    "examples = \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\\n\"\n",
    "\n",
    "for i in range(num_examples):\n",
    "    num = int(random() * num_samples)\n",
    "    hyp = ds['train'][num]['hyp']\n",
    "    tgt = ds['train'][num]['tgt']\n",
    "    label = ds['train'][num]['label']\n",
    "    examples += f\"\\nExample {i+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: {label}\\n\"\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(mapped_ds):\n",
    "    prompts = []\n",
    "    for hyp, tgt in zip(mapped_ds[\"hyp\"], mapped_ds[\"tgt\"]):\n",
    "        prompts.append(f\"{examples}\\n Example {num_examples+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: \")\n",
    "    return {'prompts' : prompts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d60880207e8484a834dc5970d9268c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts'],\n",
       "        num_rows: 499\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prompt, batched=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(mapped_ds):\n",
    "    input_ids = tokenizer(mapped_ds['prompts'], padding=True, truncation=True, max_length=500, return_tensors='pt').input_ids.cuda()\n",
    "    output = model.generate(inputs=input_ids, temperature=0.01, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=5)\n",
    "    decoded_output = tokenizer.batch_decode(output)\n",
    "    return {'output' : decoded_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e28d1a70746bea9b6e2985bfafc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/fborra/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output'],\n",
       "        num_rows: 499\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_synthetic_label(mapped_ds):\n",
    "    syn_labels = []\n",
    "    for item in mapped_ds['output']:\n",
    "        if \"Not\" in item.splitlines()[-1]:\n",
    "            syn_labels.append(\"Not Hallucination\")\n",
    "        else:\n",
    "            syn_labels.append(\"Hallucination\")\n",
    "    return {'synthetic_labels' : syn_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8209a731def4a5a8647304663a528c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output', 'synthetic_labels'],\n",
       "        num_rows: 499\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(extract_synthetic_label, batched=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751503006012024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for a, b in zip(ds['train']['label'], ds['train']['synthetic_labels']):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'label': 'Not Hallucination',\n",
       " 'model': '',\n",
       " 'ref': 'tgt',\n",
       " 'hyp': '(informal) A test to determine whether something has a certain vibe.',\n",
       " 'task': 'DM',\n",
       " 'tgt': '(slang) An impromptu attempt to ascertain mood, opinions, or attributes.',\n",
       " 'p(Hallucination)': 0.4,\n",
       " 'src': \"Usually we 'll listen to a track . It just depends . Sometimes they have a funny premise or a certain vibe and we 'll make something oriented towards that premise or vibe . If it passes the <define> vibe check </define> , we kick things off .\",\n",
       " 'prompts': \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: Capable of being parachuted.\\n<TGT>: Capable of being deployed by parachute.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: (vulgar, slang, derogatory) A contemptible person.\\n<TGT>: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\\n<LABEL>: Hallucination\\n\\nExample 3\\n<HYP>: Let's go?\\n<TGT>: Should we go?\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: (nautical) A service in which the crew of a vessel does not speak.\\n<TGT>: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: (informal) A man who works out at a gym.\\n<TGT>: (slang) A man who spends much of his free time working out at a gym.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: (informal) A test to determine whether something has a certain vibe.\\n<TGT>: (slang) An impromptu attempt to ascertain mood, opinions, or attributes.\\n<LABEL>: \",\n",
       " 'output': \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: Capable of being parachuted.\\n<TGT>: Capable of being deployed by parachute.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: (vulgar, slang, derogatory) A contemptible person.\\n<TGT>: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\\n<LABEL>: Hallucination\\n\\nExample 3\\n<HYP>: Let's go?\\n<TGT>: Should we go?\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: (nautical) A service in which the crew of a vessel does not speak.\\n<TGT>: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: (informal) A man who works out at a gym.\\n<TGT>: (slang) A man who spends much of his free time working out at a gym.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: (informal) A test to determine whether something has a certain vibe.\\n<TGT>: (slang) An impromptu attempt to ascertain mood, opinions, or attributes.\\n<LABEL>:  Not Hallucination\\n\",\n",
       " 'synthetic_labels': 'Not Hallucination'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels for New Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_column():\n",
    "    tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / \"train.model-agnostic.json\")])\n",
    "    tr_ds = tr_ds.map(lambda x: {'labels' : []})\n",
    "    tr_ds['train'].to_json(str(BASE_DIR / \"train_labeled_SOLAR.model-agnostic.json\"))\n",
    "\n",
    "#create_empty_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fb8dd7de1e4dc8a6d51b52a62373bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4562fc25516e4566b683610971f02961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa2d1828c75454ba7a0beedb54d7f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / \"train_labeled_SOLAR.model-agnostic.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c88d1c66fc6448b859dc25572087fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8ed5ef34424779b4f67795f970de25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e29cf63d604b0f895ba62e8b08021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(extract_synthetic_label, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88641e95ddd458da88f3f20eef880c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_prediction(mapped_ds):\n",
    "    mapped_ds['labels'].append(mapped_ds['synthetic_labels'])\n",
    "    return mapped_ds\n",
    "\n",
    "tr_ds = tr_ds.map(add_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': \"Please tell me I'm right.\",\n",
       " 'src': 'Скажи мне, пожалуйста, что я прав.',\n",
       " 'task': 'MT',\n",
       " 'ref': 'either',\n",
       " 'tgt': \"Please tell me I'm right.\",\n",
       " 'model': '',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'prompts': \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: Capable of being parachuted.\\n<TGT>: Capable of being deployed by parachute.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: (vulgar, slang, derogatory) A contemptible person.\\n<TGT>: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\\n<LABEL>: Hallucination\\n\\nExample 3\\n<HYP>: Let's go?\\n<TGT>: Should we go?\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: (nautical) A service in which the crew of a vessel does not speak.\\n<TGT>: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: (informal) A man who works out at a gym.\\n<TGT>: (slang) A man who spends much of his free time working out at a gym.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: Please tell me I'm right.\\n<TGT>: Please tell me I'm right.\\n<LABEL>: \",\n",
       " 'output': \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: Capable of being parachuted.\\n<TGT>: Capable of being deployed by parachute.\\n<LABEL>: Not Hallucination\\n\\nExample 2\\n<HYP>: (vulgar, slang, derogatory) A contemptible person.\\n<TGT>: (vulgar, slang, derogatory, offensive) One who has a very small penis; an inadequate male lover.\\n<LABEL>: Hallucination\\n\\nExample 3\\n<HYP>: Let's go?\\n<TGT>: Should we go?\\n<LABEL>: Not Hallucination\\n\\nExample 4\\n<HYP>: (nautical) A service in which the crew of a vessel does not speak.\\n<TGT>: (military, informal, sometimes, capitalized, possibly, _, dated) The navy.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: (informal) A man who works out at a gym.\\n<TGT>: (slang) A man who spends much of his free time working out at a gym.\\n<LABEL>: Not Hallucination\\n\\n Example 6\\n<HYP>: Please tell me I'm right.\\n<TGT>: Please tell me I'm right.\\n<LABEL>:  Not Hallucination\\n\",\n",
       " 'synthetic_labels': 'Not Hallucination'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'][3099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e014d03b7f4de2b32fafa935099d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "79334943"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'].to_json(str(BASE_DIR / \"train_labeled_SOLAR.model-agnostic.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
