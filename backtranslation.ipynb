{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts, model, tokenizer, language=\"fr\"):\n",
    "    # Prepare the text data into appropriate format for the model\n",
    "    template = lambda text: f\"{text}\" if language == \"en\" else f\">>{language}<< {text}\"\n",
    "    src_texts = [template(text) for text in texts]\n",
    "\n",
    "    # Tokenize the texts\n",
    "    encoded = tokenizer.prepare_seq2seq_batch(src_texts,\n",
    "                                              return_tensors='pt')\n",
    "    \n",
    "    # Generate translation using model\n",
    "    translated = model.generate(**encoded)\n",
    "\n",
    "    # Convert the generated tokens indices back into text\n",
    "    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    return translated_texts\n",
    "\n",
    "def back_translate(texts, target_model, target_tokenizer, source_model, source_tokenizer, target_lang=\"fr\", source_lang=\"en\" ):\n",
    "    # Translate to target language\n",
    "    fr_texts = translate(texts, target_model, target_tokenizer, \n",
    "                         language=target_lang)\n",
    "\n",
    "    # Translate from target language back to source language\n",
    "    back_translated_texts = translate(fr_texts, source_model, source_tokenizer, \n",
    "                                      language=source_lang)\n",
    "    \n",
    "    return back_translated_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "target_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
    "target_tokenizer = MarianTokenizer.from_pretrained(target_model_name)\n",
    "target_model = MarianMTModel.from_pretrained(target_model_name)\n",
    "\n",
    "\n",
    "en_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
    "en_tokenizer = MarianTokenizer.from_pretrained(en_model_name)\n",
    "en_model = MarianMTModel.from_pretrained(en_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is so cool', 'I hated the food', 'They were very helpful'] \n",
      " ['This is so great.', 'I hated food.', 'They were very helpful.']\n"
     ]
    }
   ],
   "source": [
    "en_texts = ['This is so cool', 'I hated the food', 'They were very helpful']\n",
    "source_lang=\"en\"\n",
    "target_lang=\"es\"\n",
    "\n",
    "aug_texts = back_translate(en_texts, \n",
    "                           target_model=target_model, target_tokenizer=target_tokenizer,\n",
    "                           source_model=en_model, source_tokenizer=en_tokenizer, \n",
    "                           source_lang=source_lang, target_lang=target_lang)\n",
    "print(en_texts,\"\\n\",aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual dataset Transaltion: performed on Validation model aware and agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>labels</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resembling or characteristic of a weasel.</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The writer had just entered into his eighteent...</td>\n",
       "      <td>Resembling a weasel (in appearance).</td>\n",
       "      <td></td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternative form of sheath knife</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Sailors ' and fishermen 's &lt;define&gt; sheath - k...</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(obsolete) A short period of time.</td>\n",
       "      <td>tgt</td>\n",
       "      <td>As to age , Bead could not form any clear impr...</td>\n",
       "      <td>(poetic) An instant, a short moment.</td>\n",
       "      <td></td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(slang) An incel.</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Because redpillers are usually normies or &lt;def...</td>\n",
       "      <td>(incel, _, slang) A man of a slightly lower ra...</td>\n",
       "      <td></td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Not Hallucination, Halluci...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An island in Lienchiang County, Taiwan.</td>\n",
       "      <td>tgt</td>\n",
       "      <td>On the second day of massive live - fire drill...</td>\n",
       "      <td>An island in Dongyin, Lienchiang, Taiwan, in t...</td>\n",
       "      <td></td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         hyp  ref   \n",
       "0  Resembling or characteristic of a weasel.  tgt  \\\n",
       "1           Alternative form of sheath knife  tgt   \n",
       "2         (obsolete) A short period of time.  tgt   \n",
       "3                          (slang) An incel.  tgt   \n",
       "4    An island in Lienchiang County, Taiwan.  tgt   \n",
       "\n",
       "                                                 src   \n",
       "0  The writer had just entered into his eighteent...  \\\n",
       "1  Sailors ' and fishermen 's <define> sheath - k...   \n",
       "2  As to age , Bead could not form any clear impr...   \n",
       "3  Because redpillers are usually normies or <def...   \n",
       "4  On the second day of massive live - fire drill...   \n",
       "\n",
       "                                                 tgt model task   \n",
       "0               Resembling a weasel (in appearance).         DM  \\\n",
       "1                                                  .         DM   \n",
       "2               (poetic) An instant, a short moment.         DM   \n",
       "3  (incel, _, slang) A man of a slightly lower ra...         DM   \n",
       "4  An island in Dongyin, Lienchiang, Taiwan, in t...         DM   \n",
       "\n",
       "                                              labels              label   \n",
       "0  [Hallucination, Not Hallucination, Not Halluci...  Not Hallucination  \\\n",
       "1  [Hallucination, Hallucination, Hallucination, ...      Hallucination   \n",
       "2  [Not Hallucination, Not Hallucination, Not Hal...  Not Hallucination   \n",
       "3  [Not Hallucination, Not Hallucination, Halluci...  Not Hallucination   \n",
       "4  [Not Hallucination, Not Hallucination, Not Hal...  Not Hallucination   \n",
       "\n",
       "   p(Hallucination)  \n",
       "0               0.2  \n",
       "1               0.8  \n",
       "2               0.0  \n",
       "3               0.2  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"Jack_Data\\val.model-agnostic.json\"\n",
    "file_transformed_path = r\"Jack_Data\\val.model-agnostic-backtranslated.json\"\n",
    "with open(file_path) as f:\n",
    "   data = json.load(f)\n",
    "   \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hyp_bt\"] = back_translate(df[\"hyp\"], \n",
    "                           target_model=target_model, target_tokenizer=target_tokenizer,\n",
    "                           source_model=en_model, source_tokenizer=en_tokenizer, \n",
    "                           source_lang=source_lang, target_lang=target_lang)\n",
    "\n",
    "df[\"tgt_bt\"] = back_translate(df[\"tgt\"], \n",
    "                           target_model=target_model, target_tokenizer=target_tokenizer,\n",
    "                           source_model=en_model, source_tokenizer=en_tokenizer, \n",
    "                           source_lang=source_lang, target_lang=target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(file_transformed_path, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
