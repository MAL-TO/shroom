{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/data1/malto/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Quantized LLM and Few-Shot Learning to Generate Synthetic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "#model_name_or_path = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
    "#revision = \"gptq-3bit-128g-actorder_True\"\n",
    "\n",
    "model_name_or_path = \"TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ\"\n",
    "revision = \"gptq-8bit-32g-actorder_True\"\n",
    "\n",
    "# tasks MT, DM, PG\n",
    "\n",
    "TASK_TYPE = \"PG\"\n",
    "BATCH_SIZE = 40\n",
    "BASE_DIR = Path(\"/data1/malto/shroom\")\n",
    "\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-128g-actorder_True\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=revision)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "if tokenizer.pad_token == None: # apparently Mixtral does not have a padding token in tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd39c34587947dc90a68ab44682e62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src'],\n",
       "    num_rows: 125\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"json\", data_files=[\"/data1/malto/shroom/val.model-agnostic.json\"]).shuffle()\n",
    "ds['train'] = ds['train'].filter(lambda x: x['task'] == TASK_TYPE)\n",
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\n",
      "\n",
      "Example 1\n",
      "<HYP>: There's no way this is going to happen.\n",
      "<TGT>: This can't happen.\n",
      "<LABEL>: Hallucination\n",
      "\n",
      "Example 2\n",
      "<HYP>: Take a close look at it.\n",
      "<TGT>: Take a good look.\n",
      "<LABEL>: Not Hallucination\n",
      "\n",
      "Example 3\n",
      "<HYP>: What do you think I'm, like, a monster, like, \"A monster\"?\n",
      "<TGT>: You think I'm some kind of a monster?\n",
      "<LABEL>: Hallucination\n",
      "\n",
      "Example 4\n",
      "<HYP>: We don't have the money to risk it, all right?\n",
      "<TGT>: We can't risk that.\n",
      "<LABEL>: Hallucination\n",
      "\n",
      "Example 5\n",
      "<HYP>: You're going somewhere else?\n",
      "<TGT>: What's your point?\n",
      "<LABEL>: Hallucination\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = 5\n",
    "num_samples = len(ds['train'])\n",
    "examples = \"[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\INST]\\n\"\n",
    "\n",
    "for i in range(num_examples):\n",
    "    num = int(random() * num_samples)\n",
    "    hyp = ds['train'][num]['hyp']\n",
    "    tgt = ds['train'][num]['tgt']\n",
    "    label = ds['train'][num]['label']\n",
    "    examples += f\"\\nExample {i+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: {label}\\n\"\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(mapped_ds):\n",
    "    hyp = mapped_ds[\"hyp\"]\n",
    "    tgt = mapped_ds[\"tgt\"] if mapped_ds['ref'] != \"src\" else mapped_ds['src']\n",
    "    prompt = f\"{examples}\\n Example {num_examples+1}\\n<HYP>: {hyp}\\n<TGT>: {tgt}\\n<LABEL>: \"\n",
    "    return {'prompts' : prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897da62491484735a90a2fcd5a07c123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prompt)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(mapped_ds):\n",
    "    input_ids = tokenizer(mapped_ds['prompts'], padding=True, truncation=True, max_length=500, return_tensors='pt').input_ids.cuda()\n",
    "    output = model.generate(inputs=input_ids, temperature=0.01, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=5)\n",
    "    decoded_output = tokenizer.batch_decode(output)\n",
    "    return {'output' : decoded_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a40de47c3b406796bde3ac32b8778b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/fborra/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_synthetic_label(mapped_ds):\n",
    "    syn_labels = []\n",
    "    for item in mapped_ds['output']:\n",
    "        if \"Not\" in item.splitlines()[-1]:\n",
    "            syn_labels.append(\"Not Hallucination\")\n",
    "        else:\n",
    "            syn_labels.append(\"Hallucination\")\n",
    "    return {'synthetic_labels' : syn_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6663449bcbff40a58061e9000f6755d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'label', 'model', 'ref', 'hyp', 'task', 'tgt', 'p(Hallucination)', 'src', 'prompts', 'output', 'synthetic_labels'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.map(extract_synthetic_label, batched=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for a, b in zip(ds['train']['label'], ds['train']['synthetic_labels']):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['Not Hallucination',\n",
       "  'Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'label': 'Not Hallucination',\n",
       " 'model': '',\n",
       " 'ref': 'either',\n",
       " 'hyp': \"That's what he's saying.\",\n",
       " 'task': 'PG',\n",
       " 'tgt': 'Yeah, he said that.',\n",
       " 'p(Hallucination)': 0.2,\n",
       " 'src': \"That's what he said.\",\n",
       " 'prompts': '[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: There\\'s no way this is going to happen.\\n<TGT>: This can\\'t happen.\\n<LABEL>: Hallucination\\n\\nExample 2\\n<HYP>: Take a close look at it.\\n<TGT>: Take a good look.\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: What do you think I\\'m, like, a monster, like, \"A monster\"?\\n<TGT>: You think I\\'m some kind of a monster?\\n<LABEL>: Hallucination\\n\\nExample 4\\n<HYP>: We don\\'t have the money to risk it, all right?\\n<TGT>: We can\\'t risk that.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: You\\'re going somewhere else?\\n<TGT>: What\\'s your point?\\n<LABEL>: Hallucination\\n\\n Example 6\\n<HYP>: That\\'s what he\\'s saying.\\n<TGT>: Yeah, he said that.\\n<LABEL>: ',\n",
       " 'output': '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: There\\'s no way this is going to happen.\\n<TGT>: This can\\'t happen.\\n<LABEL>: Hallucination\\n\\nExample 2\\n<HYP>: Take a close look at it.\\n<TGT>: Take a good look.\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: What do you think I\\'m, like, a monster, like, \"A monster\"?\\n<TGT>: You think I\\'m some kind of a monster?\\n<LABEL>: Hallucination\\n\\nExample 4\\n<HYP>: We don\\'t have the money to risk it, all right?\\n<TGT>: We can\\'t risk that.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: You\\'re going somewhere else?\\n<TGT>: What\\'s your point?\\n<LABEL>: Hallucination\\n\\n Example 6\\n<HYP>: That\\'s what he\\'s saying.\\n<TGT>: Yeah, he said that.\\n<LABEL>:  Not Hallucination\\n',\n",
       " 'synthetic_labels': 'Not Hallucination'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels for New Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_column():\n",
    "    tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / \"train.model-agnostic.json\")])\n",
    "    tr_ds = tr_ds.map(lambda x: {'labels' : []})\n",
    "    tr_ds['train'] = tr_ds['train'].filter(lambda x: x['task'] == TASK_TYPE)\n",
    "    tr_ds['train'].to_json(str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\"))\n",
    "\n",
    "#create_empty_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eeb83b6e7145ac8c94ee79c21512e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c959264d6a554dd688d7e5c6d1c79f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8ed3f5e47e49838175eeef4e519acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = load_dataset(\"json\", data_files=[str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc0bbf2d6f54a0d9078f5bcf996e974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3fd4f227fb4d14bbf8a2c620a22bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(generate_prediction, batched=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5139b9e8f54a47b58219ac29f48657d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_ds = tr_ds.map(extract_synthetic_label, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a16e755df94f98ae6b43a249b6b013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_prediction(mapped_ds):\n",
    "    mapped_ds['labels'].append(mapped_ds['synthetic_labels'])\n",
    "    return mapped_ds\n",
    "\n",
    "tr_ds = tr_ds.map(add_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': '♪ I got the joy, joy, joy, joy Down in my heart ♪',\n",
       " 'src': 'I got the joy, joy, joy, joy Down in my heart',\n",
       " 'task': 'PG',\n",
       " 'ref': 'src',\n",
       " 'tgt': '',\n",
       " 'model': '',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'prompts': '[INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: There\\'s no way this is going to happen.\\n<TGT>: This can\\'t happen.\\n<LABEL>: Hallucination\\n\\nExample 2\\n<HYP>: Take a close look at it.\\n<TGT>: Take a good look.\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: What do you think I\\'m, like, a monster, like, \"A monster\"?\\n<TGT>: You think I\\'m some kind of a monster?\\n<LABEL>: Hallucination\\n\\nExample 4\\n<HYP>: We don\\'t have the money to risk it, all right?\\n<TGT>: We can\\'t risk that.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: You\\'re going somewhere else?\\n<TGT>: What\\'s your point?\\n<LABEL>: Hallucination\\n\\n Example 6\\n<HYP>: ♪ I got the joy, joy, joy, joy Down in my heart ♪\\n<TGT>: I got the joy, joy, joy, joy Down in my heart\\n<LABEL>: ',\n",
       " 'output': '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] The following are examples of pairs of hyp and tgt sentences that can either be Hallucination or Not Hallucination depending on how similar they are [\\\\INST]\\n\\nExample 1\\n<HYP>: There\\'s no way this is going to happen.\\n<TGT>: This can\\'t happen.\\n<LABEL>: Hallucination\\n\\nExample 2\\n<HYP>: Take a close look at it.\\n<TGT>: Take a good look.\\n<LABEL>: Not Hallucination\\n\\nExample 3\\n<HYP>: What do you think I\\'m, like, a monster, like, \"A monster\"?\\n<TGT>: You think I\\'m some kind of a monster?\\n<LABEL>: Hallucination\\n\\nExample 4\\n<HYP>: We don\\'t have the money to risk it, all right?\\n<TGT>: We can\\'t risk that.\\n<LABEL>: Hallucination\\n\\nExample 5\\n<HYP>: You\\'re going somewhere else?\\n<TGT>: What\\'s your point?\\n<LABEL>: Hallucination\\n\\n Example 6\\n<HYP>: ♪ I got the joy, joy, joy, joy Down in my heart ♪\\n<TGT>: I got the joy, joy, joy, joy Down in my heart\\n<LABEL>:  Not Hallucination (',\n",
       " 'synthetic_labels': 'Not Hallucination'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7a58a3083241dfb47c225dbcdb9ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20068245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds['train'].to_json(str(BASE_DIR / f\"train_labeled_{TASK_TYPE}_SOLAR.model-agnostic.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
